{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GfnOdJr6FGw",
        "outputId": "e17b6a7b-1170-45ff-8df5-7dbdcf9787ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/365.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/365.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q newspaper3k langchain_community langchain openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv('/content/drive/MyDrive/Active Loop RAG/api.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL705K2YJinA",
        "outputId": "39ee6827-7621-4b6b-81ce-f43c5f8e3a41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from newspaper import Article"
      ],
      "metadata": {
        "id": "rM0J_Ed6JmuO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "}\n",
        "\n",
        "article_url = \"https://molgorithm.medium.com/what-is-add-norm-as-soon-as-possible-178fc0836381\"\n",
        "\n",
        "session = requests.Session()"
      ],
      "metadata": {
        "id": "eUjT4Mj8JtQQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  response = session.get(article_url, headers=headers, timeout=10)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    article = Article(article_url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "\n",
        "    print(f\"Title: {article.title}\")\n",
        "    print(f\"Text: {article.text}\")\n",
        "  else:\n",
        "    print(f\"Failed to gecth the article due to {response.status_code} error.\")\n",
        "except Exception as e:\n",
        "  print(f\"Error occured while fetchting the article {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqG0XxltJxEA",
        "outputId": "41ad067a-0adb-41aa-e62c-e6e34c8b672b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: What is Add & Norm, as quick as possible?\n",
            "Text: Part 1: Residual Connection (Add)\n",
            "\n",
            "Residual connection, also known as skip connection, is a technique used in deep neural networks to facilitate the training of very deep architectures. This technique was introduced in ResNet (Residual Networks) by Kaiming He et al. in 2015 [1]. This network was based on a concept called as Residual Learning. The main idea of this concept is to allow the input to a layer to bypass the layer’s operations and be added directly to the layer’s output.\n",
            "\n",
            "Figure 1: Residual Connection\n",
            "\n",
            "The layers operation can be anything like Linear Transformations, Non-Linear Transformations, Normalization, Dropout, Pooling, etc.\n",
            "\n",
            "Now to understand how residual connection works, let’s look into an example:\n",
            "\n",
            "If you design a multi-layered neural network and it’s underlying function is h(x) where x is the input to this subnetwork. Your goal is to make it model the target function h(x).\n",
            "\n",
            "Residual learning re-parameterizes this subnetwork, and lets the parameter layers represent a “residual function.” In other words, instead of approximating the underlying function h(x), the model will be forced to approximate a residual function f(x).\n",
            "\n",
            "Ideally, y = h(x). After residual connection, y = h(x) + x\n",
            "\n",
            "So, instead of estimating h(x), we estimate f(x) = h(x) — x\n",
            "\n",
            "The operation of adding the input (+x) is done using “skip connection,” as shown below in the figure 2&3.\n",
            "\n",
            "Figure 2&3: Traditional Learning & Residual Learning [2]\n",
            "\n",
            "Advantage of Residual Learning in Transformers is to facilitate signal propagation in both backward and forward paths which solves the problem of vanishing gradients. Complex networks with deeper layers like transformer suffers from vanishing gradient problems and skip connection helps restore the diminishing gradients by performing the identity mapping. To understand this mathematically, let’s see how it is done mathematically.\n",
            "\n",
            "Forward propagation\n",
            "\n",
            "From the above figure, we now know that y = f(x) + x, this y can be an input to another set of layer in the network but to keep it as simple as possible we will not assume that for now.\n",
            "\n",
            "So for now our general relationship for FP will be:\n",
            "\n",
            "y = f(x) + x\n",
            "\n",
            "Backward propagation\n",
            "\n",
            "This is where the residual connection addresses the vanishing gradient problem. To compute the gradients we will consider the partial derivate of a loss function ε with respect to the input x. Using the formula above our back propagation equation will be:\n",
            "\n",
            "Equation 1: Backpropagation in residual learning\n",
            "\n",
            "With this equation, even if ∂f(x) gradient happens to diminish the overall gradient will not vanish due to an extra ∂ε/∂y.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "wZIJ4ex0KqKy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_title = article.title\n",
        "article_text = article.text"
      ],
      "metadata": {
        "id": "j_eQcqJBLKuQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are an intelligent assistant that concisely sumarizes the articles\n",
        "\n",
        "Here's the article you want to summarize.\n",
        "\n",
        "========================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "========================\n",
        "\n",
        "Your task is to summarize the above given article.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ciy68ntuLSJ_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(article_title = article_title, article_text = article_text)\n",
        "\n",
        "messages = [HumanMessage(content=prompt)]"
      ],
      "metadata": {
        "id": "ZEbBu6IVLtgQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name='gpt-4', temperature=0)"
      ],
      "metadata": {
        "id": "_nvA5UjWM13M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "  summary = chat.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVPg83JhNJSg",
        "outputId": "cda7cbfa-2d15-4709-b79b-bb2dbbe44479"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-ba3de3a5ba68>:2: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
            "  summary = chat(messages)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej_K_v3cOyWH",
        "outputId": "57f86455-e980-4589-ce04-ae6f29f5836b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 781\n",
            "\tPrompt Tokens: 627\n",
            "\tCompletion Tokens: 154\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.02805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(textwrap.wrap(summary.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Z9IZZZnaNi4f",
        "outputId": "1c68e4ca-9d37-4e60-99c8-5474eeabf61b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The article explains the concept of Add & Norm, focusing on the Residual Connection (Add) aspect. Residual connection, also known as skip connection, is a technique used in deep neural networks to facilitate the training of deep architectures. It was introduced in ResNet by Kaiming He et al. in 2015. The technique allows the input to a layer to bypass the layer’s operations and be added directly to the layer’s output. This re-parameterizes the network, forcing the model to approximate a residual function instead of the underlying function. The advantage of this in Transformers is that it facilitates signal propagation in both backward and forward paths, solving the problem of vanishing gradients. The article also explains the mathematical aspect of forward and backward propagation in residual learning.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt for bulleted list answer"
      ],
      "metadata": {
        "id": "oiSGIpqxOQnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NiEhHTdhN26_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(article_title=article.title, article_text = article.text)"
      ],
      "metadata": {
        "id": "X5IALV3NOTgw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "  summary = chat.invoke([HumanMessage(content=prompt)])"
      ],
      "metadata": {
        "id": "85ZTF7e9Oc_P"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puC4VLeDO_sA",
        "outputId": "0500c4e8-e8ad-4515-de1b-c5c62c4e5898"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- The article discusses the concept of Add & Norm, focusing on the Residual Connection (Add) aspect.\n",
            "- Residual connection, also known as skip connection, is a technique used in deep neural networks to facilitate the training of very deep architectures.\n",
            "- This technique was introduced in ResNet (Residual Networks) by Kaiming He et al. in 2015 and is based on the concept of Residual Learning.\n",
            "- Residual Learning allows the input to a layer to bypass the layer’s operations and be added directly to the layer’s output.\n",
            "- The layers operation can include Linear Transformations, Non-Linear Transformations, Normalization, Dropout, Pooling, etc.\n",
            "- Residual learning re-parameterizes a subnetwork, forcing the model to approximate a residual function f(x) instead of the underlying function h(x).\n",
            "- After residual connection, the equation becomes y = h(x) + x, so instead of estimating h(x), we estimate f(x) = h(x) — x.\n",
            "- The operation of adding the input (+x) is done using “skip connection.”\n",
            "- The advantage of Residual Learning in Transformers is to facilitate signal propagation in both backward and forward paths, solving the problem of vanishing gradients.\n",
            "- Complex networks with deeper layers like transformers suffer from vanishing gradient problems and skip connection helps restore the diminishing gradients by performing the identity mapping.\n",
            "- The article also explains the mathematical relationship for forward propagation (y = f(x) + x) and backward propagation, where the residual connection addresses the vanishing gradient problem.\n",
            "- Even if the ∂f(x) gradient diminishes, the overall gradient will not vanish due to an extra ∂ε/∂y in the back propagation equation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2xCYClBO5qv",
        "outputId": "f405034a-3211-4dcf-e1c8-b2c5291c5551"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 980\n",
            "\tPrompt Tokens: 632\n",
            "\tCompletion Tokens: 348\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.03984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WArrLtdPSof"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}