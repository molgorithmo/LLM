{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Role Prompt\n",
        "\n",
        "Asking the LLM to assume a specific role to help provide a context or perspectice for the task.\n",
        "\n",
        "- Specify the role, e.g., \"As a copywriter, ...\""
      ],
      "metadata": {
        "id": "kO7DWJZ-t166"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S0g-jnzt036",
        "outputId": "6756a92f-1790-44b4-d90f-12b69ac3c975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai langchain_community python-dotenv --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53pBjjHUB-It",
        "outputId": "e3e17c2e-de50-48e0-c6ed-32832ba4b94d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv('/content/drive/MyDrive/Active Loop RAG/api.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErGhJ9S7uXYT",
        "outputId": "b1f4760f-08b0-4708-ef09-0e2e39ddb3c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "zfdRRRZruZDu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0)"
      ],
      "metadata": {
        "id": "1TmdRX_CuiGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3b7fe5-3d0e-4137-e459-ed3c3f3fa261"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-eca3edb999ea>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
        "What's cool song title for a song about {theme} in the year {year}?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OXazhu_9usIO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"theme\", \"year\"],\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "id": "KlFpPvv7vrTO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\"theme\": \"interstellar travel\", \"year\":\"3030\"}"
      ],
      "metadata": {
        "id": "KI0-woYvv0q_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "gvMPySHOv-xu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(input_data)"
      ],
      "metadata": {
        "id": "rc7PzAEKwBF_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Theme: interstellar travel\")\n",
        "print(\"Year: 3030\")\n",
        "print(\"AI-generated song title:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtcALCxIwEP_",
        "outputId": "99416d88-fe3b-4a9d-9393-c17602a1c648"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theme: interstellar travel\n",
            "Year: 3030\n",
            "AI-generated song title: \n",
            "\"Galactic Odyssey: Journey to 3030\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few shot prompting"
      ],
      "metadata": {
        "id": "UzwovIApwXNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "qrb0k3e0wLUu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
        "    {\"color\":\"blue\", \"emotion\": \"serenity\"},\n",
        "    {\"color\":\"green\", \"emotion\": \"tranquility\"}\n",
        "]"
      ],
      "metadata": {
        "id": "eHP8aldCwiS5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_formatter_template = \"\"\"\n",
        "Color: {color}\n",
        "Emotion: {emotion}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables = [\"color\", \"emotion\"],\n",
        "    template=example_formatter_template\n",
        ")"
      ],
      "metadata": {
        "id": "Cuwl0OlWw2qQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
        "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor:{color}\\nEmotion:\",\n",
        "    input_variables=['color'],\n",
        "    example_separator='\\n'\n",
        ")"
      ],
      "metadata": {
        "id": "I70ejLMNxKLu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_prompt = few_shot_prompt.format(color=\"purple\")"
      ],
      "metadata": {
        "id": "cXSq0Fytxtmu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = few_shot_prompt | llm"
      ],
      "metadata": {
        "id": "d_SUvT-7x2ce"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\"color\": \"purple\"}"
      ],
      "metadata": {
        "id": "nrdZZVKYCdn1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "  response = chain.invoke(input_data)"
      ],
      "metadata": {
        "id": "hj64Lq8nx6oe"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Color: purple\")\n",
        "print(\"Emotion:\", response)\n",
        "print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xowI3djyEk-",
        "outputId": "36f40c37-b8bb-4110-84a6-7a99b7096068"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color: purple\n",
            "Emotion:  royalty\n",
            "Tokens Used: 64\n",
            "\tPrompt Tokens: 63\n",
            "\tCompletion Tokens: 1\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $9.65e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain Prompting"
      ],
      "metadata": {
        "id": "OLWXYrenDBQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from  textwrap import TextWrapper, wrap"
      ],
      "metadata": {
        "id": "OjjCB4kF2efi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0)"
      ],
      "metadata": {
        "id": "0pK0XLAUDHYE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_question = \"\"\"\n",
        "What is the name of the famous scientist who developed {concept}?\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt_question = PromptTemplate(template = template_question, input_variables=['concept'])"
      ],
      "metadata": {
        "id": "Ycb8Ytv3DQQl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_fact = \"\"\"\n",
        "Provide a brief description of {scientist}'s {concept}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt_fact = PromptTemplate(template = template_fact, input_variables = ['scientist', 'concept'])"
      ],
      "metadata": {
        "id": "GBG7D3-uDsK5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_question = prompt_question | llm\n",
        "\n",
        "concept = 'the general theorey of relativity'\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "  scientist_who = chain_question.invoke('the general theorey of relativity')"
      ],
      "metadata": {
        "id": "SFI1VguLDukU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_fact = prompt_fact | llm\n",
        "\n",
        "input_data = {'scientist': str(scientist_who), 'concept': str(concept)}\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "  response = chain_fact.invoke(input_data)"
      ],
      "metadata": {
        "id": "YaUh8zT9EWfj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n'.join(wrap(text=response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT5ExC5uEYKl",
        "outputId": "1fe97829-d2a7-4671-cbe2-23e9e9cccbe1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The general theory of relativity, developed by Albert Einstein in\n",
            "1915, is a theory of gravity that explains the relationship between\n",
            "space and time. It states that massive objects, such as planets and\n",
            "stars, cause a curvature in the fabric of space-time, which is\n",
            "perceived as the force of gravity. This theory also predicts that the\n",
            "path of light is bent by the presence of massive objects, which has\n",
            "been confirmed through observations of gravitational lensing. The\n",
            "general theory of relativity has been a cornerstone of modern physics\n",
            "and has been crucial in understanding the behavior of the universe on\n",
            "a large scale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Well structured few shots prompt"
      ],
      "metadata": {
        "id": "ZTKZmAoVITg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "yaPmNX2dEoTW"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0)"
      ],
      "metadata": {
        "id": "fwQuRfXEIlAU"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What is the secret to happiness?\",\n",
        "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How can I become more productive?\",\n",
        "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "ebW7o3imIuTW"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "35GG7PinJEm0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(template=example_template, input_variables=[\"query\", \"answer\"])"
      ],
      "metadata": {
        "id": "ml9fjMbtJKgm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
        "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
        "examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\""
      ],
      "metadata": {
        "id": "SClf6L5GJWZG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator='\\n\\n'\n",
        ")"
      ],
      "metadata": {
        "id": "p-btdj_QJh73"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = few_shot_prompt_template | llm"
      ],
      "metadata": {
        "id": "LwEbXjIfJ8JG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "  response = chain.invoke({\"query\": \"What are some tips for improving communication skills?\"})"
      ],
      "metadata": {
        "id": "2I-oS_60KHBl"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n'.join(wrap(response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG3oYnLJKWLF",
        "outputId": "9edb872e-ca45-4ea4-b852-de9bdfdb5eb0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active listening, being clear and concise, and practicing empathy are\n",
            "all important skills for effective communication. Also, don't be\n",
            "afraid to ask for clarification or feedback to ensure understanding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic prompting - LengthBasedExample"
      ],
      "metadata": {
        "id": "YkHJvWsZLnvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain_openai --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK5ZsSU6NxY-",
        "outputId": "309b4803-2036-48f5-97ac-13116d9e1af9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "3qgYt_X-NgLW"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"How do you feel today?\",\n",
        "        \"answer\": \"As an AI, I don't have feelings, but I've got jokes!\"\n",
        "    }, {\n",
        "        \"query\": \"What is the speed of light?\",\n",
        "        \"answer\": \"Fast enough to make a round trip around Earth 7.5 times in one second!\"\n",
        "    }, {\n",
        "        \"query\": \"What is a quantum computer?\",\n",
        "        \"answer\": \"A magical box that harnesses the power of subatomic particles to solve complex problems.\"\n",
        "    }, {\n",
        "        \"query\": \"Who invented the telephone?\",\n",
        "        \"answer\": \"Alexander Graham Bell, the original 'ringmaster'.\"\n",
        "    }, {\n",
        "        \"query\": \"What programming language is best for AI development?\",\n",
        "        \"answer\": \"Python, because it's the only snake that won't bite.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the capital of France?\",\n",
        "        \"answer\": \"Paris, the city of love and baguettes.\"\n",
        "    }, {\n",
        "        \"query\": \"What is photosynthesis?\",\n",
        "        \"answer\": \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"\n",
        "    }, {\n",
        "        \"query\": \"What is the tallest mountain on Earth?\",\n",
        "        \"answer\": \"Mount Everest, Earth's most impressive bump.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the most abundant element in the universe?\",\n",
        "        \"answer\": \"Hydrogen, the basic building block of cosmic smoothies.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the largest mammal on Earth?\",\n",
        "        \"answer\": \"The blue whale, the original heavyweight champion of the world.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the fastest land animal?\",\n",
        "        \"answer\": \"The cheetah, the ultimate sprinter of the animal kingdom.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the square root of 144?\",\n",
        "        \"answer\": \"12, the number of eggs you need for a really big omelette.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the average temperature on Mars?\",\n",
        "        \"answer\": \"Cold enough to make a Martian wish for a sweater and a hot cocoa.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "uYm6FA6zKhxF"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    max_length=100\n",
        ")"
      ],
      "metadata": {
        "id": "2gG3OwJmLtf2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dynamic_prompt_template = FewShotPromptTemplate(\n",
        "    example_selector = example_selector,\n",
        "    example_prompt = example_prompt,\n",
        "    prefix = prefix,\n",
        "    suffix = suffix,\n",
        "    input_variables = [\"query\"],\n",
        "    example_separator=\"\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "FKQgtgaxMDJF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "9lTcf4eQNZCO"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = dynamic_prompt_template | llm"
      ],
      "metadata": {
        "id": "37_Nbcg9Nrdk"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\"query\": \"Who invented the telephone?\"}\n",
        "\n",
        "response = chain.invoke(input_data)"
      ],
      "metadata": {
        "id": "Gy0TdjiGN8E2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7anWJec5OGAU",
        "outputId": "4945028d-8cec-4aab-9fda-7e8cf96a571d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexander Graham Bell is credited with inventing the telephone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "evrpXht7PIgQ"
      }
    }
  ]
}